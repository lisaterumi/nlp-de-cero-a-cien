# Introducción al Procesamiento del Lenguaje Natural y Word Embeddings

Esta semana el tema fue word embeddings, un concepto fundamental de procesamiento de lenguaje natural. Aquí les compartimos recursos adicionales así como publicaciones por si les interesa entrar con mayor profundidad en el tema. Así mismo, hay un cuaderno de colab con ejercicios para que puedan entender mejor el concepto.

## Recursos adicionales

* https://jalammar.github.io/illustrated-word2vec/: Esta es una guía ilustrada que explica de manera muy intuitiva los conceptos de word2vec.
* https://lena-voita.github.io/nlp_course/word_embeddings.html: Esta es otra explicación de word embeddings y contiene tanto publicaciones como preguntas para hacer reflexión adicional.
* [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/) capítulo 6 secciones 3 a 8.

## Papers

* [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781). Este es el paper original de word2vec.
* [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://papers.nips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf): Este paper discute los sesgos que pueden existir en los embeddings.